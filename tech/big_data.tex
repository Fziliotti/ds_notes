\section{A Small Piece of Big Data}

\subsection{Introdução}

\frame{
	\begin{block}{Big-Data}
``Big data is a term for data sets that are so large or complex that traditional data processing application software is inadequate to deal with them.''
	\end{block}

Ciclo convencional:
\begin{itemize}
	\item Coleta
	\item Armazenamento
	\item Análise
	\item Consulta
	\item Compartilhamento
	\item Visualização
	\item Atualização
	\item ...
\end{itemize}

\href{https://en.wikipedia.org/wiki/Big_data}{Fonte}
}

\begin{frame}{Áreas}
Grandes massas de dados:
\begin{itemize}
	\item Propaganda
	\item Astronomia
	\item Ciência
	\item e-governos
	\item meteorologia
	\item \emph{genomics}
	\item ...
\end{itemize}
\end{frame}

\begin{frame}{Dados}
\begin{itemize}
	\item Internet das coisas
	\item sensoriamento remoto
	\item suas fotos
	\item logs de software
	\item RFID
	\item redes de sensores
	\item ...
\end{itemize}
\end{frame}

\begin{frame}{O quê?}
	Quão grande é ``big'' o suficiente? \pause Depende dos dados, ferramentas, e capacidade de manipulá-los. \pause Uma vez dado um passo, o alvo passa a ser o próximo passo. \pause Isso quer dizer que vai de alguns TB até Petabytes, dependendo do problema.
\end{frame}


\begin{frame}{O quê?}
\begin{block}{Gartner, 2012}
Big data is high volume, high velocity, and/or high variety information assets that require new forms of processing to enable enhanced decision making, insight discovery and process optimization.
\end{block}

\begin{itemize}
	\item Volume: incapacidade de armazenar todos os dados; apenas observe e guarde conclusões
	\item Velocidade: dados passando em ``tempo real''
	\item Variedade: imagens, vídeos, áudio, temperatura,...
	\pause
	\item Machine learning para automação de extração de informação, por exemplo, detecção de padrões, sem se preocupar com o porquê dos mesmos.
\end{itemize}
\end{frame}



\begin{frame}{Como lidar?}
\begin{itemize}
	\item Bancos de dados colunares
	\item Stream DBs
	\item ...
	\item \alert{MapReduce}
\end{itemize}
\end{frame}

\subsection{Google FS}

\begin{frame}{Google FS}
\begin{itemize}
	\item Google, 2003
	\item File System
	\item Dados recuperados da Internet usados em consultas
	\item Milhões de arquivos de múltiplos GB
	\item Chunks de 64MB (``blocos do disco'')
	\item Operações comuns são appends ou reads
	\item Servidores/discos/memórias estão sempre falhando
	\item Centenas de clientes concorrentes no mesmo arquivo
\end{itemize}
\includegraphics[width=.6\textwidth]{images/gfs3}
\end{frame}

\begin{frame}{Google FS}
\includegraphics[width=.7\textwidth]{images/gfs2}

\begin{itemize}
\item Clusters de nós ``comuns''
\item Master node: metadata
\item Chunk servers: data
\item Permite usar um cluster como um único HD elástico na rede.
\end{itemize}

\href{https://www.cs.rutgers.edu/~pxk/417/lectures/l-dfs.html}{Fonte}
\end{frame}

\begin{frame}{Google FS}
\includegraphics[width=.7\textwidth]{images/gfs5}

\begin{itemize}
	\item Apps recebem \emph{leases} de acesso direto aos dados
	\item Atomic commitment garante consistência entre réplicas
\end{itemize}

\href{http://google-file-system.wikispaces.asu.edu/}{Fonte}
\end{frame}

\begin{frame}[fragile,allowframebreaks]{Google FS: Consistência }
\includegraphics[width=\textwidth]{images/gfs6}

\framebreak
\begin{enumerate}
\item Application sends the file name and data to the GFS client.
\item GFS Client send the file name and chunk index to master
\item Master sends the identity of the primary and other secondary replicas to the client.
\item Client caches this information. Client contacts master again only when primary is unreachable or it sends a reply saying it does not holds the lease anymore.
\item Considering the network topology the client sends the data to all the replicas.This improves performance. GFS separates data flow from the control flow. Replicas store the data in their LRU buffers till it is used.
\item After all replicas receiving of the data, client sends write request to the primary. Primary decides the mutation order. It applies this order to its local copy.
\item Primary sends the write request to all the secondary replicas. They perform write according to serial order decided by the primary.
\item After completing the operation all secondary acknowledge primary.
\item Primary replies the client about completion of the operation. In case of the errors that is when some of the secondary fail to write client request is supposed to be fail.This leaves modified chunk inconsistent. \item Client handles this by retrying the failed mutation. 
\end{enumerate}

\href{http://google-file-system.wikispaces.asu.edu/}{Fonte}
\end{frame}

\begin{frame}{Map Reduce}
\begin{itemize}
	\item Google, 2004
	\item Processamento distribuído
	\item Processa arquivos no Google FS
\end{itemize}
\includegraphics[width=.6\textwidth]{images/gfs4}
\end{frame}

\frame{\alert{leases?}}

\begin{frame}{Chubby}
	\begin{itemize}
		\item Google, 2006
	\end{itemize}
	\includegraphics[width=.6\textwidth]{images/chubby1}
\end{frame}





\begin{frame}{Hadoop}
\begin{itemize}
	\item HDFS: Hadoop Distributed File System
	\item Map Reduce
	\item Yahoo!
	\item Open source em 2011, 1.0.0
	\item 2012, 2.0.0,
	\item 2017, 3.0.0
	\item nov 2018, 2.9.2
\end{itemize}
\end{frame}


\begin{frame}{Hadoop Ecosystem}
\begin{itemize}
	\item Hive: data warehouse
	\item Spark: 
	\item Kafka
	\item Yarn
	\item Pig: linguagem para especificação de data flow.
	\item HBase: banco de dados estruturado
	\item Sqoop
	\item Flume
	\item Oozie
	\item Avro: serialização
	\item Mahout: machine learning
\end{itemize}
\end{frame}



\begin{frame}{HDFS}
\begin{itemize}
	\item Distribuído
	\item Escalável
	\item Cost effective
	\item Tolerante a falhas
	\item Alta vazão
\end{itemize}
\end{frame}


\begin{frame}{Arquitetura}
\begin{itemize}
	\item Rack e rack failure
	\item Top of rack switch
	\item Core switch
	\item Name Node: nomes das pastas e arquivos
	\item Data Node: conteúdo dos arquivos
	\item Cliente
\end{itemize}
\end{frame}

\begin{frame}{Arquitetura}
\begin{itemize}
	\item Crie arquivo: cliente -> name node
	\item Escreva um block (e.g., 128MB): cliente
	\item Aloque block: cliente -> name node
	\item Salve os dados: cliente -> data node
	\item Heartbeat block report: data node -> name node
	\item Dados são replicados (RF configurado por arquivo): Data node -> data node
\end{itemize}
\end{frame}



\begin{frame}{Name node}
Dados em memory e edit log.

\begin{itemize}
	\item Name node é um SPOF? 
	\item Quorum Journal Manager replica edit log.
	\item Standby Name Node
	\item Zookeeper usado para decidir quem é o líder
	\item Secondary Name Node replica checkpoint da imagem em memória.
\end{itemize}
\end{frame}

\subsection{MapReduce}
\begin{frame}{MapReduce}
	\begin{itemize}
		\item Programação funcional
		\item Map: (map length (() (a) (a b c)) = (0 1 3))
		\item Fold/Reduce: (reduce + (1 2 3)) = 6
	\end{itemize}
\end{frame}


\begin{frame}{MapReduce}
	\begin{itemize}
		\item Não há dependência entre os dados
		\item Dados divididos em \emph{shards}
		\item Execução paralela e distribuída
		\item Trabalhador recebe um shard
		\item Mestre agrega valores
		\item Milhares de processos
		\item Petabytes de dados
	\end{itemize}
\end{frame}

\begin{frame}{MapReduce}
	\begin{itemize}
		\item Shards são arquivos do GFS/HDFS/EC2
		\item Função mapeada a cada shard
		\item Resultado é lista de chaves e valores
		\item Agregação acontece por chaves
		\item Resultado são arquivos no GFS/HDFS/EC2
	\end{itemize}
\end{frame}

\begin{frame}{MapReduce}
	\includegraphics[width=.8\textwidth]{images/mapreduce1}
\end{frame}

\begin{frame}{MapReduce}
	\includegraphics[width=.8\textwidth]{images/mapreduce2}
\end{frame}


\subsection{Laboratório}

\begin{frame}[fragile]{Exemplo}
\begin{lstlisting}[language=java]
import ...

public class WordCount 
{
 public static class TokenizerMapper 
 extends Mapper<Object, Text, Text, IntWritable>
 {
  private final static IntWritable one = new IntWritable(1);
  private Text word = new Text();

  public void map(Object key, Text value, Context context) 
   throws IOException, InterruptedException 
  {
   StringTokenizer itr = new StringTokenizer(value.toString());
   while (itr.hasMoreTokens()) 
   {
    word.set(itr.nextToken());
    context.write(word, one);
   }
  } 
 }
...
\end{lstlisting}
\end{frame}

\begin{frame}[fragile]{Exemplo}
\begin{lstlisting}[language=java]
...
 public static class IntSumReducer 
  extends Reducer<Text,IntWritable,Text,IntWritable> 
 { 
  private IntWritable result = new IntWritable();
  public void reduce(Text key, Iterable<IntWritable> values, Context context) throws IOException, InterruptedException 
  {
   int sum = 0;
   for (IntWritable val : values) 
    sum += val.get();
   result.set(sum);
   context.write(key, result);
  }
 }
	
 public static void main(String[] args) throws Exception 
 {
  ...
 }
}
	
\end{lstlisting}
\href{https://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html#Example:_WordCount_v1.0}{Fonte}
\end{frame}

\frame{\url{https://youtu.be/DJPwV2ge9m0?list=PLkz1SCf5iB4dw3jbRo0SYCk2urRESUA3v}}




